{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c04526e6-8f48-42ac-afde-7d8dda770feb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Generic Box\n",
    "This code communicates with a component. The component was launched with the command below from the root of the repository:\n",
    "\n",
    "```shell\n",
    "$ docker run --rm -it -p 4061:8061 -v ./src/external1.py=/workspace/external.py generic\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03414be6-450d-4ec1-9bd2-6aab13d4156f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image as PIL_image\n",
    "import numpy as np\n",
    "\n",
    "from importlib.machinery import SourceFileLoader\n",
    "#In case of importing files from other directory\n",
    "clip_pb2 = SourceFileLoader(\"clip_pb2\",\"../protos/clip_pb2.py\").load_module()\n",
    "clip_pb2_grpc = SourceFileLoader(\"clip_pb2_grpc\",\"../protos/clip_pb2_grpc.py\").load_module()\n",
    "\n",
    "import grpc\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760efcd5-5bd7-48eb-9cd3-6300f5b14f28",
   "metadata": {},
   "source": [
    "## Set parameters (GRPC) and data\n",
    "Set IP and port of the service (the same used in docker run), input data and call the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef8f328c-3721-442b-9fb4-2c37754347dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read dog.jpg: 0.37 MB\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "#target='printart.isr.ist.utl.pt:8061'\n",
    "target='localhost:8061'\n",
    "\n",
    "texts = [\"a diagram\", \"a dog\", \"a cat\", \"garden\", \"grass\", \"dirt road\"]\n",
    "\n",
    "file_paths = ['dog.jpg']\n",
    "\n",
    "image_byte_list = []\n",
    "for path in file_paths:\n",
    "    # Open the file in binary read mode ('rb') and read its entire content\n",
    "    with open(path, 'rb') as f:\n",
    "        image_bytes = f.read()\n",
    "        image_byte_list.append(image_bytes)\n",
    "        print(f\"Read {path}: {len(image_bytes) / (1024 * 1024):.2f} MB\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "request = clip_pb2.CLIPRequest(images= image_byte_list,\n",
    "                               texts=texts) # list of strings\n",
    "\n",
    "# List of file paths (example paths â€” replace with your actual ones)\n",
    "\n",
    "channel_opt = [('grpc.max_send_message_length', 512 * 1024 * 1024), ('grpc.max_receive_message_length', 512 * 1024 * 1024)]\n",
    "channel=grpc.insecure_channel(target,options=channel_opt)\n",
    "estimator_stub = clip_pb2_grpc.CLIPServiceStub(channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dec30ee-2660-40b2-bff2-8772fd1ab2ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "_InactiveRpcError",
     "evalue": "<_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNKNOWN\n\tdetails = \"Exception calling application: CUDA out of memory. Tried to allocate 20.00 MiB. GPU \"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv6:%5B::1%5D:8061 {grpc_message:\"Exception calling application: CUDA out of memory. Tried to allocate 20.00 MiB. GPU \", grpc_status:2}\"\n>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31m_InactiveRpcError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#Name of the method in the service\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m response = \u001b[43mestimator_stub\u001b[49m\u001b[43m.\u001b[49m\u001b[43mForward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#After finishing channel.close\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/grpc/_channel.py:1178\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable.__call__\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m   1166\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\n\u001b[32m   1167\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1168\u001b[39m     request: Any,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1173\u001b[39m     compression: Optional[grpc.Compression] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1174\u001b[39m ) -> Any:\n\u001b[32m   1175\u001b[39m     state, call = \u001b[38;5;28mself\u001b[39m._blocking(\n\u001b[32m   1176\u001b[39m         request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[32m   1177\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1178\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_end_unary_response_blocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/grpc/_channel.py:1006\u001b[39m, in \u001b[36m_end_unary_response_blocking\u001b[39m\u001b[34m(state, call, with_call, deadline)\u001b[39m\n\u001b[32m   1004\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m state.response\n\u001b[32m   1005\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1006\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[31m_InactiveRpcError\u001b[39m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNKNOWN\n\tdetails = \"Exception calling application: CUDA out of memory. Tried to allocate 20.00 MiB. GPU \"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv6:%5B::1%5D:8061 {grpc_message:\"Exception calling application: CUDA out of memory. Tried to allocate 20.00 MiB. GPU \", grpc_status:2}\"\n>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1757519125.297943   65688 chttp2_transport.cc:1335] ipv6:%5B::1%5D:8061: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {grpc_status:14, http2_error:2}\n"
     ]
    }
   ],
   "source": [
    "#Name of the method in the service\n",
    "response = estimator_stub.Forward(request)\n",
    "#After finishing channel.close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac3a110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.5494, 0.4505],\n",
       "        [0.5494, 1.0000, 0.4608],\n",
       "        [0.4505, 0.4608, 1.0000]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1757428280.961997    1104 chttp2_transport.cc:1335] ipv6:%5B::1%5D:8061: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {http2_error:2, grpc_status:14}\n"
     ]
    }
   ],
   "source": [
    "torch.load(io.BytesIO(response.similarities))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
