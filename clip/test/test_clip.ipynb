{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c04526e6-8f48-42ac-afde-7d8dda770feb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Generic Box\n",
    "This code communicates with a component. The component was launched with the command below from the root of the repository:\n",
    "\n",
    "```shell\n",
    "$ docker run --rm -it -p 4061:8061 -v ./src/external1.py=/workspace/external.py generic\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03414be6-450d-4ec1-9bd2-6aab13d4156f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image as PIL_image\n",
    "import numpy as np\n",
    "\n",
    "from importlib.machinery import SourceFileLoader\n",
    "#In case of importing files from other directory\n",
    "clip_pb2 = SourceFileLoader(\"clip_pb2\",\"../protos/clip_pb2.py\").load_module()\n",
    "clip_pb2_grpc = SourceFileLoader(\"clip_pb2_grpc\",\"../protos/clip_pb2_grpc.py\").load_module()\n",
    "\n",
    "import grpc\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760efcd5-5bd7-48eb-9cd3-6300f5b14f28",
   "metadata": {},
   "source": [
    "## Set parameters (GRPC) and data\n",
    "Set IP and port of the service (the same used in docker run), input data and call the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef8f328c-3721-442b-9fb4-2c37754347dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read car.jpg: 0.09 MB\n",
      "Read dog.jpg: 0.37 MB\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "#target='printart.isr.ist.utl.pt:8061'\n",
    "target='localhost:8061'\n",
    "\n",
    "texts = [\"a diagram\", \"a dog\", \"a cat\", \"garden\", \"grass\", \"dirt road\", \"race car\"]\n",
    "\n",
    "file_paths = [\"car.jpg\",\"dog.jpg\"]\n",
    "\n",
    "image_byte_list = []\n",
    "for path in file_paths:\n",
    "    # Open the file in binary read mode ('rb') and read its entire content\n",
    "    with open(path, 'rb') as f:\n",
    "        image_bytes = f.read()\n",
    "        image_byte_list.append(image_bytes)\n",
    "        print(f\"Read {path}: {len(image_bytes) / (1024 * 1024):.2f} MB\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "request = clip_pb2.CLIPRequest(images= image_byte_list,\n",
    "                               texts=texts) # list of strings\n",
    "\n",
    "# List of file paths (example paths â€” replace with your actual ones)\n",
    "\n",
    "channel_opt = [('grpc.max_send_message_length', 512 * 1024 * 1024), ('grpc.max_receive_message_length', 512 * 1024 * 1024)]\n",
    "channel=grpc.insecure_channel(target,options=channel_opt)\n",
    "estimator_stub = clip_pb2_grpc.CLIPServiceStub(channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dec30ee-2660-40b2-bff2-8772fd1ab2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name of the method in the service\n",
    "response = estimator_stub.Forward(request)\n",
    "#After finishing channel.close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ac3a110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.7670e-05, 1.8047e-04, 9.4234e-04, 1.3780e-05, 3.7842e-03, 2.6548e-03,\n",
       "         9.9233e-01],\n",
       "        [1.4549e-03, 3.1245e-01, 5.5151e-03, 8.3253e-03, 6.7070e-01, 1.9874e-04,\n",
       "         1.3577e-03]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(io.BytesIO(response.similarity)).softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8062703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0547, -0.0061,  0.0495,  ..., -0.6638, -0.1281, -0.4950],\n",
       "        [ 0.1447,  0.0225, -0.2909,  ..., -0.4472, -0.3420,  0.1798],\n",
       "        [ 0.1981, -0.2040, -0.1533,  ..., -0.4514, -0.5664,  0.0596],\n",
       "        ...,\n",
       "        [-0.0472, -0.4781,  0.0119,  ..., -0.1359, -0.1047,  0.3215],\n",
       "        [ 0.0298, -0.2795, -0.0423,  ...,  0.4853, -0.2102,  0.0906],\n",
       "        [ 0.1785, -0.3823, -0.1179,  ...,  0.2795, -0.1647, -0.1460]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(io.BytesIO(response.text_emb))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
