{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c04526e6-8f48-42ac-afde-7d8dda770feb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Generic Box\n",
    "This code communicates with a component. The component was launched with the command below from the root of the repository:\n",
    "\n",
    "```shell\n",
    "$ docker run --rm -it -p 4061:8061 -v ./src/external1.py=/workspace/external.py generic\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03414be6-450d-4ec1-9bd2-6aab13d4156f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import grpc\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "#In case of importing files from other directory\n",
    "from importlib.machinery import SourceFileLoader\n",
    "\n",
    "vggt_pb2 = SourceFileLoader(\"vggt_pb2\",\"../protos/vggt_pb2.py\").load_module()\n",
    "vggt_pb2_grpc = SourceFileLoader(\"vggt_pb2_grpc\",\"../protos/vggt_pb2_grpc.py\").load_module()\n",
    "\n",
    "import PIL.Image as PIL_image\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.io import loadmat,savemat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760efcd5-5bd7-48eb-9cd3-6300f5b14f28",
   "metadata": {},
   "source": [
    "## Set parameters (GRPC) and data\n",
    "Set IP and port of the service (the same used in docker run), input data (image in a matfile) and call the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef8f328c-3721-442b-9fb4-2c37754347dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read /home/manuelf/mast3r/images_in/piv/6.png: 0.17 MB\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "#target='printart.isr.ist.utl.pt:8061'\n",
    "target='localhost:8061'\n",
    "# List of file paths (example paths â€” replace with your actual ones)\n",
    "file_paths = [\n",
    "    'images/00.jpg',\n",
    "    'images/01.jpg',\n",
    "]\n",
    "\n",
    "#list all files in a certain directory\n",
    "import os\n",
    "directory = \"/home/manuelf/mast3r/images_in/piv\"\n",
    "file_paths = [os.path.join(directory, f) for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))][0:1]\n",
    "\n",
    "# List to hold the binary data of each image\n",
    "image_byte_list = []\n",
    "for path in file_paths:\n",
    "    # Open the file in binary read mode ('rb') and read its entire content\n",
    "    with open(path, 'rb') as f:\n",
    "        image_bytes = f.read()\n",
    "        image_byte_list.append(image_bytes)\n",
    "        print(f\"Read {path}: {len(image_bytes) / (1024 * 1024):.2f} MB\")\n",
    "\n",
    "config_json = {\n",
    "    \"aispgradio\": {\n",
    "        \"command\": \"3d_infer\",\n",
    "        \"parameters\": {\n",
    "            \"device\": \"cuda:0\", # TODO: implement this\n",
    "            \"conf_vis\": 50.0\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "request = vggt_pb2.VGGTRequest(images=image_byte_list, config_json = json.dumps(config_json))\n",
    "\n",
    "#Para imagens muito grandes buffer grande\n",
    "channel_opt = [('grpc.max_send_message_length', 512 * 1024 * 1024), ('grpc.max_receive_message_length', 512 * 1024 * 1024)]\n",
    "channel=grpc.insecure_channel(target,options=channel_opt)\n",
    "estimator_stub = vggt_pb2_grpc.VGGTServiceStub(channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dec30ee-2660-40b2-bff2-8772fd1ab2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name of the method in the service\n",
    "response = estimator_stub.Forward(request)\n",
    "#After finishing channel.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5a4db88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 518, 518, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def bytes_to_tensor(b: bytes) -> torch.Tensor:\n",
    "    return torch.load(io.BytesIO(b))\n",
    "\n",
    "depthmap = bytes_to_tensor(response.depth)\n",
    "\n",
    "#plt.imshow(depthmap.squeeze()[0], cmap='gray')\n",
    "bytes_to_tensor(response.world_points).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ea272e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pythreejs as three\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets.embed import embed_minimal_html\n",
    "\n",
    "# 1. Generate random data for the points\n",
    "\n",
    "# Create random (x, y, z) coordinates between -5 and 5\n",
    "positions = bytes_to_tensor(response.world_points).squeeze().numpy().reshape(-1,3)[::2]\n",
    "colors = bytes_to_tensor(response.images).permute(0,2,3,1).numpy().reshape(-1,3)[::2] # Normalize to [0, 1]\n",
    "\n",
    "# 2. Create the geometry and assign the point positions\n",
    "# The data needs to be a float32 array\n",
    "point_geometry_colored = three.BufferGeometry(\n",
    "    attributes={\n",
    "        'position': three.BufferAttribute(positions.astype('float32')),\n",
    "        # === KEY CHANGE 2: Add the 'color' attribute to the geometry ===\n",
    "        'color': three.BufferAttribute(colors.astype('float32'))\n",
    "    }\n",
    ")\n",
    "\n",
    "# 3. Create a material for the points\n",
    "point_material_colored = three.PointsMaterial(\n",
    "    size=0.01, \n",
    "    # === KEY CHANGE 3: Tell the material to use the geometry's colors ===\n",
    "    vertexColors='VertexColors'\n",
    ")\n",
    "\n",
    "# 4. Create the Points object\n",
    "points_colored = three.Points(geometry=point_geometry_colored,\n",
    "                               material=point_material_colored)\n",
    "\n",
    "# 5. Set up the scene, camera, and renderer\n",
    "camera_colored = three.PerspectiveCamera(\n",
    "    position=[0, 0, 12],\n",
    "    fov=50,\n",
    "    aspect=1.5,\n",
    ")\n",
    "camera_colored.up = [0, -1, 0]\n",
    "\n",
    "# Add an axes helper to see the orientation\n",
    "axes_colored = three.AxesHelper(size=5)\n",
    "\n",
    "scene_colored = three.Scene(children=[\n",
    "    points_colored, \n",
    "    axes_colored,\n",
    "    three.AmbientLight(color='#cccccc')\n",
    "])\n",
    "\n",
    "renderer_colored = three.Renderer(\n",
    "    camera=camera_colored, \n",
    "    scene=scene_colored, \n",
    "    controls=[three.OrbitControls(controlling=camera_colored)],\n",
    "    width=1200, \n",
    "    height=900\n",
    ")\n",
    "\n",
    "# Display the renderer in the notebook\n",
    "renderer_colored\n",
    "\n",
    "# Save as standalone HTML file\n",
    "widget = widgets.VBox([renderer_colored])\n",
    "with io.StringIO() as f:\n",
    "    embed_minimal_html(f, views=[widget], title=\"3D Point Cloud\")\n",
    "    f.seek(0)\n",
    "    file_like_object = f.read()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
